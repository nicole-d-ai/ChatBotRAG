# âœ¨ Chatbot RAG con Mistral + ChromaDB

Este proyecto implementa un chatbot inteligente utilizando la arquitectura RAG (Retrieval-Augmented Generation), donde un modelo LLM genera respuestas basadas en mi propia base de conocimientos.

Fue desarrollado como trabajo prÃ¡ctico de la materia Procesamiento del habla.

ğŸš€ Â¿QuÃ© hace este proyecto?

âœ”ï¸ Construye un chatbot capaz de responder preguntas sobre una app de oficios
âœ”ï¸ Usa una base de Q&A creada manualmente
âœ”ï¸ Implementa RAG para recuperar informaciÃ³n relevante
âœ”ï¸ Compara dos modelos de embeddings
âœ”ï¸ EvalÃºa la calidad del chatbot con mÃ©tricas de recuperaciÃ³n
âœ”ï¸ Genera respuestas usando un modelo LLM de HuggingFace

ğŸ§  Arquitectura utilizada
ğŸ” 1. RecuperaciÃ³n (Retrieval)

Se utiliza ChromaDB como base vectorial.
Los textos se vectorizan usando dos modelos:

ğŸŸ¢ MiniLM-L6-v2

ğŸŸ£ Jina Embeddings v2 Base ES

Cada uno genera una colecciÃ³n distinta para poder compararlos.

ğŸ“ 2. GeneraciÃ³n (Generation)

Para generar las respuestas finales se usa:

ğŸ¦™ Mistral-7B-Instruct v0.2

El LLM recibe:

la pregunta del usuario

ğŸ“š Dataset

Se construyeron dos datasets:

* Base de conocimiento: ~20 preguntas reales de clientes y profesionales

* Dataset de evaluaciÃ³n: nuevas preguntas creadas para testear recuperaciÃ³n

ğŸ“¦ LibrerÃ­as principales

* transformers â€” modelos LLM y tokenizers

* sentence-transformers â€” embeddings

* chromadb â€” base de datos vectorial

* torch â€” tensores y device mapping

* numpy, pandas â€” soporte general

ğŸ§ª EvaluaciÃ³n del Chatbot

Se midieron:

* Context Precision

* Context Recall

* Resultados promedio (k=3):

* Precision â‰ˆ 0.28

* Recall â‰ˆ 0.85

ğŸ“Œ MiniLM y Jina recuperaron chunks con rendimiento similar, pero MiniLM generÃ³ respuestas mÃ¡s naturales y Ãºtiles, por lo que se eligiÃ³ como embedding final.

ğŸ ConclusiÃ³n

El proyecto demuestra cÃ³mo integrar:

* una base de conocimiento propia

* modelos de embeddings

* ChromaDB

* un LLM moderno

â€¦para construir un chatbot funcional con arquitectura RAG.
La mejor combinaciÃ³n encontrada fue:

ğŸ‘‰ MiniLM-L6-v2 + Mistral-7B-Instruct

ğŸ™Œ Autor

Nicole Desire Ferreyra â€” Ciencia de Datos e IA
GitHub: nicole-d-ai

los k chunks mÃ¡s relevantes recuperados

un prompt instructivo para responder claro y corto
